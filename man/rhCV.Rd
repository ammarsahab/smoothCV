% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/smoothCV.R
\name{rhCV}
\alias{rhCV}
\title{Repeated holdout cross-validation}
\usage{
rhCV(
  fullset,
  trainsplit,
  randsplit,
  iter,
  type,
  start,
  end,
  dist,
  localoptim = F,
  alphrange,
  betarange
)
}
\arguments{
\item{fullset}{A set of univariate time series data. Can be a vector (type double) or a data.table.}

\item{trainsplit}{Proportion of observations to be used as training set}

\item{randsplit}{Proportion of observations in the set with uncertain membership.
Will be split into training and testing proportions.}

\item{iter}{Number of repetitions}

\item{type}{Type of smoothing. Can be \code{"SMA"}, \code{"DMA"}, \code{"SES"}, \code{"DES"}.}

\item{start}{(if type="SMA" or type="DMA") Starting value for m (see \code{sma.dt} and \code{dma.dt}).}

\item{end}{(if type="SMA" or type="DMA") Maximum value for m.
Must be less than or equal to the length of the training set for SMA,
or less than or equal to the length of the training set divided by two for DMA.}

\item{dist}{(if type="SMA" or type="DMA") Distance between successive values for m.
The vector of m values will be constructed as \code{seq(start,end,dist)}.}

\item{localoptim}{Whether to optimize in each training set.
If true, there is no need to provide values for alpha and beta..}

\item{alphrange}{(if type="SES" or type="DES") A vector of parameters for the level component.
Can be created using \code{seq}, or by manually specifying a vector.}

\item{betarange}{(if type="DES") A vector of parameters for the trend component.
Can be created using \code{seq}, or by manually specifying a vector.
Not used if type="SES"}
}
\value{
A data.table containing all parameter combinations during each iteration (fold) with their respective MSE and MAPE values.
Can be grouped by parameter values to obtain the mean error for each parameter value.
}
\description{
The method splits the data into a training set, a testing set, and a set which will be split into
training and testing portions based on a random number generator.
Grid search, or optimization, is then committed for k iterations
}
\examples{
fcCV(fullset=crudenow$Close, initialn=36, folds=12, type="DES", localoptim=F,
alphrange=seq(0.1,1,0.1), betarange=seq(0.1,1,0.1))
fcCV(fullset=crudenow$Close, initialn=36, folds=12, type="SMA", localoptim=F,
start=2, end=30, dist=3)
}
